name: Build

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

env:
  # Customize the CMake build type here (Release, Debug, RelWithDebInfo, etc.)
  BUILD_TYPE: Release

jobs:
  build:
    # The CMake configure and build commands are platform agnostic and should work equally well on Windows or Mac.
    # You can convert this to a matrix build if you need cross-platform coverage.
    # See: https://docs.github.com/en/free-pro-team@latest/actions/learn-github-actions/managing-complex-workflows#using-a-build-matrix
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.7", "3.8", "3.9", "3.10"]
    defaults:
      run:
        shell: bash -l {0}

    steps:
      - uses: actions/checkout@v3

      - name: Set Swap Space
        uses: pierotofy/set-swap-space@master
        with:
          swap-size-gb: 10

      - name: Install apt dependencies
        run: |
          sudo apt-get update -qq && sudo apt-get upgrade -qq -y
          sudo apt-get -qq install -y wget

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v3
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install CUDA
        uses: Jimver/cuda-toolkit@v0.2.5
        id: cuda-toolkit
        with:
          cuda: "11.2.2"
          linux-local-args: '["--toolkit"]'

      - name: Install CUDNN
        run: |
          wget -q https://developer.download.nvidia.com/compute/redist/cudnn/v8.1.1/cudnn-11.2-linux-x64-v8.1.1.33.tgz
          tar -xzf cudnn-11.2-linux-x64-v8.1.1.33.tgz
          sudo cp -P cuda/include/cudnn.h ${{steps.cuda-toolkit.outputs.CUDA_PATH}}/include
          sudo cp -P cuda/include/cudnn_version.h ${{steps.cuda-toolkit.outputs.CUDA_PATH}}/include
          sudo cp -P cuda/lib64/libcudnn* ${{steps.cuda-toolkit.outputs.CUDA_PATH}}/lib64/
          sudo chmod a+r ${{steps.cuda-toolkit.outputs.CUDA_PATH}}/lib64/libcudnn*

      - name: Test CUDA installation
        run: |
          echo "Installed CUDA version is: ${{steps.cuda-toolkit.outputs.cuda}}"
          echo "CUDA install location: ${{steps.cuda-toolkit.outputs.CUDA_PATH}}"
          which nvcc
          nvcc -V

      - name: Install conda
        uses: conda-incubator/setup-miniconda@v2.1.1
        with:
          miniconda-version: "latest"
          mamba-version: "*"
          channels: conda-forge,defaults
          channel-priority: true
          activate-environment: pipeswitch
          environment-file: env.yml
          python-version: 3.8
          auto-activate-base: false

      - name: Test conda installation
        run: |
          conda info
          conda list

      - name: Clone and build PyTorch
        env:
          CMAKE_PREFIX_PATH: ${CONDA_PREFIX:-"$(dirname $(which conda))/../"}
          MAX_JOBS: 1
          USE_CUDA: 1
          USE_CUDNN: 1
          PATH: "${{steps.cuda-toolkit.outputs.CUDA_PATH}}/bin${PATH:+:${PATH}}"
          LD_LIBRARY_PATH: "${{steps.cuda-toolkit.outputs.CUDA_PATH}}/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}"
          CUDA_HOME: "/usr/local/cuda"
        run: |
          wget -q https://github.com/pytorch/pytorch/releases/download/v1.11.0/pytorch-v1.11.0.tar.gz
          tar -xzf pytorch-v1.11.0.tar.gz
          cd pytorch-v1.11.0
          python3 setup.py install
          chmod +x ${{github.workspace}}/pytorch_plugins/overwrite.sh
          bash ${{github.workspace}}/pytorch_plugins/overwrite.sh .
          python3 setup.py install
          export PYTHONPATH=$PYTHONPATH:$PWD

      - name: Test PyTorch installation
        run: |
          python3 ${{github.workspace}}/test/pt.py

      - name: Clone and build torchvision
        run: |
          wget -q https://github.com/pytorch/vision/archive/refs/tags/v0.12.0.tar.gz
          tar -xzf v0.12.0.tar.gz
          cd vision-0.12.0
          python3 setup.py install

      - name: Install detectron2
        run: |
          python3 -m pip install 'git+https://github.com/facebookresearch/detectron2.git'
